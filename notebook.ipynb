{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6678a3bf-e7b9-4c41-aaa3-9a71d026376c",
   "metadata": {},
   "source": [
    "# Data Science | Final Project | Group 02\n",
    "\n",
    "## Identify epigenetic alterations associated with Alzheimer’s disease and classification of gene expressions between healthy and sick patients\n",
    "\n",
    "#### Carmen Calle Huerta, Christina Kirschbaum, Pushpa Koirala, Melika Moradi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b47320-9337-494f-a0af-932f496c4ca3",
   "metadata": {},
   "source": [
    "## Our Project\n",
    "\n",
    "Alzheimer’s disease is the most prevalent kind of dementia and a fatal brain ailment. More study into this illness might lead to a better understanding of the condition and more effective treatment options. \n",
    "\n",
    "In this project, ChIP-seq data for H3K27ac, H3K9ac, H3K122ac and H3K4me1 as well as RNA-seq data from the from the lateral temporal lobe of the human brain for young healthy patients, old heathy patients and patients with Alzheimers disease will be analyzed and the differences between normal aging and cognitive impairment will be explored. The epigenomic or transcriptomic profiles will be analyzed to find relevant epigenetic alterations associated with the disease and help to better understand the molecular pathophysiology underlying.\n",
    "\n",
    "Afterwards, with Machine Learning models the presence and absence of Alzheimer’s disease based on the data. The models will be built with Support Vector Machines and Random Forest.\n",
    "\n",
    "Finally, the findings will be compared to them in related papers, we will look into relevant *in vivo* experiments with model organisms and use the Genome Browser to generate ChIP-seq tracks.\n",
    "\n",
    "For our project we were inspirated by the paper:\n",
    "Nativio R, Lan Y, Donahue G et al. [\"An integrated multi-omics approach identifies\n",
    "epigenetic alterations associated with Alzheimer’s disease.\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8098004/)\n",
    "\n",
    "The data is derived from GEO, [Series GSE153875](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE153875)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a13d3",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "First, we import some of the most frequently used packages in Python. [NumPy](https://numpy.org/doc/stable/) for working with arrays, matrices and linear algebra, [pandas](https://pandas.pydata.org/docs/) for data analysis and manipulation, [matplotlib](https://matplotlib.org/) and [seaborn](https://seaborn.pydata.org/) for visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d313e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67bd37d-c0e3-41d2-98ec-f7d302110cf1",
   "metadata": {},
   "source": [
    "## Data Integration and Preprocessing RNA-seq\n",
    "\n",
    "In the next step, we import our RNA-seq data from the SubSeries GSE159699 of the SuperSeries GSE153875 with SRA-Toolkit and fastq-dump. To integrate this process into Python, the package subrocess is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf943bf2-5f35-439d-ade7-2116ab5aaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# sra numbers from accession list of our RNA-seq data from SuperSeries GSE153875 / SubSeries GSE159699\n",
    "sra_numbers = [\n",
    "    \"SRR12850830\", \"SRR12850831\", \"SRR12850832\", \"SRR12850833\", \"SRR12850834\",\n",
    "    \"SRR12850835\", \"SRR12850836\", \"SRR12850837\", \"SRR12850838\", \"SRR12850839\",\n",
    "    \"SRR12850840\", \"SRR12850841\", \"SRR12850842\", \"SRR12850843\", \"SRR12850844\",\n",
    "    \"SRR12850845\", \"SRR12850846\", \"SRR12850847\", \"SRR12850848\", \"SRR12850849\",\n",
    "    \"SRR12850850\", \"SRR12850851\", \"SRR12850852\", \"SRR12850853\", \"SRR12850854\",\n",
    "    \"SRR12850855\", \"SRR12850856\", \"SRR12850857\", \"SRR12850858\", \"SRR12850859\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844c8bf-c638-4e31-85c2-6bb4b16ba761",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code from https://erilu.github.io/python-fastq-downloader/\n",
    "\n",
    "# this will download the .sra files to ~/ncbi/public/sra/ \n",
    "for sra_id in sra_numbers:\n",
    "    print (\"Currently downloading: \" + sra_id)\n",
    "    prefetch = \"prefetch \" + sra_id\n",
    "    print (\"The command used was: \" + prefetch)\n",
    "    subprocess.call(prefetch, shell=True)\n",
    "\n",
    "# this will extract the .sra files from above into a folder named 'fastq'\n",
    "for sra_id in sra_numbers:\n",
    "    print (\"Generating fastq for: \" + sra_id)\n",
    "    fastq_dump = \"fastq-dump --outdir fastq --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip ~/ncbi/public/sra/\" + sra_id + \".sra\"\n",
    "    print (\"The command used was: \" + fastq_dump)\n",
    "    subprocess.call(fastq_dump, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5fdba-0d9e-4a51-9c1e-0d7f9bbdd596",
   "metadata": {},
   "source": [
    "After we downloaded the data, we will now preprocess it with STAR, an aligner for RNA-seq data mapping. Like in the paper of *Nativio et al.*, we will align our RNA-seq reads to the human reference genome (assembly GRCh37.75/hg19) using STAR with default parameters.\n",
    "The [fasta](http://ftp.ensembl.org/pub/release-75/fasta/homo_sapiens/dna/) and the [gtf](http://ftp.ensembl.org/pub/release-75/gtf/homo_sapiens/) file used for the genomeDir argument was downloaded from Ensembl. \n",
    "\n",
    "This will create .sam files out of the .fastq files.\n",
    "\n",
    "**Currently running**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b427ad5-0d72-4c4a-9e5f-c35f538d7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/c/Users/chris/OneDrive/Documents/GitHub/DataScience_finalProjekt_Group2\"\n",
    "path_genomeDir = \"/mnt/c/Users/chris/OneDrive/Documents/GitHub/DataScience_finalProjekt_Group2/GenomeDir/\"\n",
    "path_fastq = \"/mnt/c/Users/chris/OneDrive/Documents/GitHub/DataScience_finalProjekt_Group2/fastq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d24f8b-fb8e-4e4d-b08e-35e9c296819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSTAR --runThreadN 2 --runMode genomeGenerate --genomeDir /mnt/c/Users/chris/GenomeDir/ --genomeFastaFiles /mnt/c/Users/chris/Downloads/Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa --sjdbGTFfile /mnt/c/Users/chris/Downloads/Homo_sapiens.GRCh37.75.gtf\n",
      "\tSTAR version: 2.7.10a   compiled: 2022-01-14T18:50:00-05:00 :/home/dobin/data/STAR/STARcode/STAR.master/source\n",
      "Jun 14 22:46:07 ..... started STAR run\n",
      "Jun 14 22:46:07 ... starting to generate Genome files\n",
      "Jun 14 22:47:52 ..... processing annotations GTF\n",
      "Jun 14 22:49:33 ... starting to sort Suffix Array. This may take a long time...\n",
      "Jun 14 22:52:02 ... sorting Suffix Array chunks and saving them to disk...\n"
     ]
    }
   ],
   "source": [
    "# get Genome Index\n",
    "genomeIndex = \"STAR --runThreadN 2 --runMode genomeGenerate --genomeDir \" + path_genomeDir + \" --genomeFastaFiles \" + path + \"Homo_sapiens.GRCh37.75.dna_sm.primary_assembly.fa --sjdbGTFfile \" + path + \"Homo_sapiens.GRCh37.75.gtf\"\n",
    "subprocess.call(genomeIndex, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b890a6-a841-4a7c-b4a9-71750bd76aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run mapping\n",
    "for fastq in sra_numbers:\n",
    "    print (\"Currently aligning: \" + fastq)\n",
    "    gunzip = \"gunzip \" + path_fastq + fastq + \"_pass.fastq.gz\"\n",
    "    subprocess.call(gunzip, shell=True)\n",
    "    mapping = \"STAR --runThreadN 2 --genomeDir \" + path_genomeDir + \" --readFilesIn \" + fastq + \"_pass.fastq\"\n",
    "    subprocess.call(mapping, shell=True)\n",
    "    print(\"Done with \" + fastq)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a150c2-3234-4dad-a697-6288ee49256a",
   "metadata": {},
   "source": [
    "## Data Integration for ChIP-seq\n",
    "\n",
    "The .bed and .bw files for the ChIP-seq data were downloaded. They are available as supplementary files of the SuperSeries GSE153875 from GEO. We split them into folders for H3K27ac, H3K9ac, H3K122ac and H3K4me1 (and peaks) to get smaller sets.\n",
    "\n",
    "**Where to store the data? ChIP-seq is overall 27GB, RNA-seq in FASTQ-format 50GB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548f025-56f7-4b10-8776-fa3f6f29742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code can get the metadata (if needed) for the ChIP-seq data with the library GEOparse (similar to GEOquery).\n",
    "import GEOparse\n",
    "\n",
    "gse = GEOparse.get_GEO(geo=\"GSE153875\", destdir=\"./\")\n",
    "\n",
    "# prints the metadata for the first sample\n",
    "for gsm_name, gsm in gse.gsms.items():\n",
    "    print(\"Name: \", gsm_name)\n",
    "    print(\"Metadata:\",)\n",
    "    for key, value in gsm.metadata.items():\n",
    "        print(\" - %s : %s\" % (key, \", \".join(value)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84557ac-8979-413f-b64e-b8b20fe0b3bb",
   "metadata": {},
   "source": [
    "## Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11393845-4a5f-496a-8fea-64bed8ee0ede",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "77efda19133223beae4d8202f64c0ed7ef77e02bd33099328534a5c00204ca3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
